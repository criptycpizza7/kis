{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f202db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>Лекция 1. Основные понятия и технологии больших данных</b>\n",
    " \n",
    "- Общие понятия о больших данных, наука о данных. \n",
    "- Понятия дескриптивной, диагностической, прогностической, прескриптивной  аналитик.\n",
    "- Основные этапы жизненного цикла аналитики больших данных.  \n",
    "- Основные методы анализа больших данных. \n",
    "- Обзор основных программных средств анализа больших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e083161",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Понятие большие данные (Big Data), наука о данных (Data Science)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a2d86",
   "metadata": {},
   "source": [
    "Скорость роста генерируемых и хранимых данных растет экспоненциально. \n",
    "В статье 1965 года Гордон Мур подсчитал, что плотность транзисторов на интегральной плате увеличивается вдвое каждые два года. Этот темп роста, известный как «закон Мура», был применен ко всем аспектам вычислений,\n",
    "от тактовых частот до памяти. Считается, что темпы роста объемов данных превышают закон Мура.\n",
    "\n",
    "**Объемы данных увеличиваются более чем вдвое каждые восемнадцать месяцев.**\n",
    "\n",
    "Этот взрыв данных создает возможности для новых способов комбинирования и использования данных, а также создает значительные проблемы из-за размера обрабатываемых и анализируемых данных. \n",
    "\n",
    "Одно существенное изменение касается количества неструктурированных данных. Исторически структурированные данные обычно были в центре внимания большей части корпоративной аналитики, и обрабатывалась с помощью реляционной модели данных. \n",
    "\n",
    "В последнее время количество неструктурированных данные, такие как веб-страницы, данные социальных сетей, изображения и видео резко выросли, и тенденция указывает на увеличение использования неструктурированных данных. \n",
    "\n",
    "*Аналитика больших данных - это способность обрабатывать большие объемы и различные типы информации.*\n",
    "    \n",
    "Рассмотрим ключевые этапы в становлении понятия \"большие данные\" \n",
    "    (https://api.bigdata-msu.ru/media/uploads/2021/05/27/2021_05_25_hohlov.pdf): \n",
    "    \n",
    "*2001.* Аналитик Meta Group Даг Лэйни публикует аналитическую записку, в которой дает три основные характеристики: объем, скорость изменений и многообразие больших данных (3V = Volume, Velocity, Variety)\n",
    "    \n",
    "\n",
    "*2013-2014*. Национальный институт стандартизации и технологий США (NIST) создает рабочую группу по большим данным для стандартизации эталонной архитектуры больших данных.  В 2014 г опубликованы первые редакции основных документов NIST https://bigdatawg.nist.gov/V1_output_docs.php\n",
    "    \n",
    "*2015* Международная организация по стандартизации (ИСО) и Международная электротехническая комиссия (МЭК) публикуют предварительный доклад «Большие данные», в котором описаны проблемы и направления международной стандартизации технологий работы с большими данными.\n",
    "\n",
    "*2018* Утверждены первые международные стандарты из серии стандартов ISO/IEC 20547-X, посвященной стандартизации\n",
    "эталонной архитектуры больших данных: часть 2 «Сценарии использования и производные требования» и часть 5 «Направления стандартизации»\n",
    "    \n",
    "\n",
    "    \n",
    "*2020* Утвержден международный стандарт «Организация сетей, ориентированных на большие данные – Требования» [ITU-T Y.3652] и опубликованы рекомендации по внедрению больших данных в развивающихся странах [Y Suppl. 65], утверждены\n",
    "международные стандарты «Большие данные – Эталонная архитектура» [ITU-TY.3605] и «Большие данные – Обзор и требования к сохранению данных» [ITU-T Y.3604]\n",
    "\n",
    "*2021* Подготовлен  к публикации международный стандарт «Организация сетей, ориентированных на большие данные – Функциональная архитектура» [ITU-T Y.3653]\n",
    "    \n",
    "Для  того  чтобы  набор  данных  можно  было  считать  большими  данными,  он  должен  обладать  одной  или  несколькими  специфическими характеристиками. Большинство  этих  характеристик  данных  были  первоначально  определены  Дагом  Лейни  в  начале  2001  года,  когда он  опубликовал  свою  статью,  описывающую  влияние  объема,  скорости  и  многообразия  данных  электронной  коммерции  на  хранилища  данных  предприятия.\n",
    "    \n",
    " На текущий момент согласно NIST SP 1500-1 -- Volume 1: Definitions выделяют следующие характеристики:\n",
    "    \n",
    "**Объем (Volume)**\n",
    "    \n",
    " Предполагаемый  объем  данных,  который  обрабатывается  решениями  для  больших  данных,  является  существенным  и  постоянно  растущим.  Большие  объемы  данных  накладывают  различные  требования  по  хранению  и  обработке  данных,  а  также  к  дополнительной  подготовке  данных,  к  процессам \n",
    "сопровождения  и  управления. \n",
    "    \n",
    "Типичные  источники  данных,  которые  отвечают  за  генерацию  больших  объемов  данных,  могут  включать  в  себя:\n",
    " * онлайн-транзакции,  такие  как  розничные  точки  продаж  и  т.д.\n",
    " * научные  и  исследовательские  эксперименты,  такие  как большой  адронный  коллайдер  и  атакамский  большой  антенный  телескоп\n",
    " * сенсоры,  такие  как  GPS-сенсоры,  RFID,  смарт-счетчики  и телематика\n",
    " * социальные  сети,  такие  как  Facebook  и  Twitter\n",
    "\n",
    " Организации  и  пользователи по  всему  миру  создают  более  2,5  ЕВ  [экзабайтов)  данный  в  день.  В  качестве  сравнения:  в  настоящее  время  библиотека  Конгресса  США  содержит  более  300  ТВ (терабайтов)  данный.\n",
    "    \n",
    "**Скорость (Velocity)**\n",
    "    \n",
    "В  средах  с  большими  данными  последние  могут  поступать  с  высокими  скоростями,  и  при  этом  огромные  массивы  данных  могут  накапливаться  за  очень  короткие  промежутки  времени.  \n",
    "    \n",
    "В  зависимости  от  источника  данных  скорость  может  разной.   В тоже время для сравнения можно указать, что за  минуту  могут  быть  легко  созданы  следующие  объемы  данных:  350  тысяч  твитов,  300  часов  видеоматериалов,  загруженных  на  YouTube,  171  миллион  электронных  писем  и  330  гигабайт  данных  от  сенсоров  реактивного  двигателя.\n",
    "\n",
    "**Многообразие (Variety)**\n",
    "    \n",
    "Многообразие  данных  касается  множества  форматов  и  типов  данных,  которые  должны  поддерживаться  решениями \n",
    "для  больших  данных.  \n",
    "    \n",
    "Многообразие  данных  создает  проблемы   с  точки  зрения  интеграции  данных,  их  трансформации,  обработки  и  хранения.  В качестве примера  многообразия  данных можно указать: структурированные  данные  в  форме  финансовых  транзакций,  слабоструктурированные  данные  в  виде  электронных  писем  и  неструктурированные  данные  в  виде  изображений, текстов,  графики,  видео-  аудио-,  html,  json,  сенсорные  данные  и  метаданные.\n",
    "\n",
    "**Изменчивость (Variability)**\n",
    "    \n",
    "Кроме того, что данные могут быстро накапливаться, уже накопленные могут еще и быстро меняться. Это накладывает существенные ограничения на проектирование распределенных систем хранения данных, поскольку можно не успевать их согласовывать в разных сегментах децентрализованного хранилища: системы электронной коммерции, биржи.\n",
    "    \n",
    "\n",
    "Поскольку все эти термины начинаются на английскую букву V, такой набор часто называют \"V\".\n",
    "\n",
    "В тоже время иногда выделяют дополнительные характеристики: **достоверность (veracity)** (т.е. точность данных), ценность **value** (т.е. ценность аналитики для организации), **волатильность (volatility)** (т. е. склонность структур данных к изменению во времени - меняются форматы хранения, передачи данных) и **валидность (validity)** (т. е. пригодность данных для предполагаемого использования).\n",
    "    \n",
    "Окончательно, под большими данными будем понимать:\n",
    "  \n",
    "**Большие данные - это данные, которые  характеризуются следующими свойствами:  объем, многообразие, скорость, и (или) изменчивость, и требуют масштабируемой архитектуры для эффективного хранения, обработки и анализа.**\n",
    "    \n",
    "Как уже было указано, по многообразию данные можно классифицировать на следующие группы:\n",
    "    \n",
    "   * структурированные данные;\n",
    "   * слабоструктурированные данные;\n",
    "   * неструктурированные данные.\n",
    "\n",
    "*Структурированные  данные*  соответствуют  моделям  или  схемам  данных  и часто  хранятся  в  табличных  формах. \n",
    "\n",
    " Они  используются  для  фиксации  отношений  между  различными  объектами и  поэтому  чаще  всего  хранятся  в  реляционных  базах  данных.  Структурированные  данные  часто  генерируются корпоративными  приложениями  и  информационными  системами,  такими  как  системы  ERP  и  CRM.  Из-за  обилия инструментов  и  баз  данных,  которые  поддерживают  структурированные  данные,  они  редко  нуждаются  в  особых  подходах к  обработке  или  хранению.  Примерами  такого  типа  данных  являются  банковские  операции,  счета-фактуры  и  записи  клиентов.\n",
    "    \n",
    "*Слабоструктурированные  данные*  имеют  определенный  уровень  структуры  и  согласованности,  но  не  являются  реляционными  по  своей  природе.  Они  являются  иерархическими  или  основанными  на  графах.  Такого  рода  данные  обычно хранятся  в  файлах,  содержащих  текст.  Например,  файлы  XML  и  JSON  являются  распространенными  формами  слабоструктурированных  данных.  Ввиду текстовой  природы  этих  данных  и  их  соответствия  определенному  уровню  структуры  они  обрабатываются  легче,  чем  неструктурированные  данные.\n",
    "Примеры  общих  источников  слабоструктурированных  данных  включают  файлы  электронной  системы  документооборота  (EDI),  электронные  таблицы,  RSS-каналы  и  данные  от  сенсоров.  Слабоструктурированные  данные  часто  имеют специальные  требования  к  предварительной  обработке  и  хранению,  особенно  если  основной  формат  не  является  текстовым.  Примером  предварительной  обработки  слабоструктурированных  данных  может  быть  проверка  допустимости XML-файла  с  целью  гарантирования  соответствия  его  определению  схемы. (см. витрины данных https://data.mos.ru/)\n",
    "    \n",
    "*Данные,  которые  не  соответствуют  моделям  или  схемам \n",
    "данных,  называются  *неструктурированными  данными*.  Считается,  что  неструктурированные  данные  составляют  80% данных  любой организации.  Неструктурированные  данные имеют  более  быстрый  темп  роста,  чем  структурированные.   Форма таких данных  является  либо текстовой,  либо  бинарной  и  зачастую  передается  посредством  файлов,  которые  являются  автономными и  нереляционными.  Текстовый  файл  может  вмещать  содержимое  различных  твитов  или  постов  в  блогах.  Бинарные  файлы  чаще  представляют  собой  мультимедийные  файлы,  содержащие  изображения,  аудио-  или  видеоданные.  Технически  и  текстовые,  и  бинарные  файлы  имеют  структуру,  определенную  самим  форматом  файла,  но  этот  аспект  игнорируется,  а  понятие неструктурированное относится  к  формату  данных.\n",
    "    \n",
    "Обычно  для  обработки  и  хранения  неструктурированных  данных  требуется  специализированная  логика.  Например,  для  воспроизведения  видеофайла  важно  наличие  правильного  кодека.  Неструктурированные  данные  нельзя  напрямую  обработать  или  запросить  с  помощью  SQL.  Если  их необходимо  хранить  в  реляционной  базе  данных,  то  они  сохраняются  в  таблице  как  большие  бинарные  объекты  (Binary Large  Object  —  BLOB).\n",
    "\n",
    "\n",
    "Рассмотрим теперь термин **наука о данных**. Согласно NIST:\n",
    "    \n",
    "**Наука о данных - это методология синтеза полезных знаний непосредственно из данных через процесс открытия или формулировки гипотез и проверки гипотез.**\n",
    "    \n",
    "*Специалист по данным (data scientist)* - это практик, обладающий достаточными знаниями в предметной области (Domain Expertise), статистики и машинном обучении (Statistics & Machine Learning), инжиниринга для управления сквозными процессами обработки данных в жизненном цикле данных (Engineering). \n",
    "    \n",
    "Более наглядно этот набор компетенций описан на рисунке в виде диаграммы Вена-Эйлера.\n",
    "\n",
    "<img src=\"ris1.jpg\" height=\"300\" width=\"300\">\n",
    "\n",
    "\n",
    "Хотя этот полный набор навыков в редком случае может присутствовать в отдельном человеке, также возможно, что эти навыки охватываются членами команды."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f570c10d-dc8d-41c7-a171-9b118b4e06c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Различные виды аналитик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5644255-f6f8-43ef-b183-6480b7b2f19e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Анализ данных представляет собой процесс исследования данных для поиска фактов, отношений, шаблонов, идей и/или тенденций. Общая цель анализа данных заключается в том, чтобы поддерживать принятие более обоснованных решений. Простым примером анализа данных является анализ данных по продаже мороженого с целью определить, каким образом количество проданных рожков связано со среднесуточной температурой воздуха. Результаты такого анализа могли бы стать обоснованием для решения о количестве мороженого, которое магазин должен заказать в зависимости от прогноза погоды. Выполнение анализа данных помогает установить закономерности и взаимосвязи между анализируемыми данными.\n",
    "\n",
    "Существуют четыре основные категории аналитики, которые различаются производимыми результатами:\n",
    "\n",
    " - дескриптивная аналитика\n",
    " - диагностическая аналитика\n",
    " - прогностическая аналитика\n",
    " - прескриптивная аналитика\n",
    "\n",
    "*Дескриптивная аналитика* \n",
    "\n",
    "Дескриптивная аналитика используется для поиска ответов на вопросы о событиях, которые уже произошли. Эта форма аналитики согласовывает данные с контекстом для генерирования информации.\n",
    "Примеры вопросов дескриптивной аналитики:\n",
    "\n",
    "Каким был объем продаж за последние 12 месяцев?\n",
    "Сколько звонков поступило в службу поддержки, упорядоченных по категориям серьезности и географическому расположению?\n",
    "Какова ежемесячная комиссия, заработанная каждым агентом по продажам?\n",
    "\n",
    "По оценкам, 80 % сгенерированных результатов аналитики являются дескриптивными по своей природе. Ориентированная на смысловую полезность, дескриптивная аналитика обеспечивается с наименьшими затратами и требует относительного базового набора навыков.\n",
    "\n",
    "Дескриптивная аналитика часто выполняется с помощью специальных отчетов или информационных панелей. Отчеты обычно статичны по своей природе и отображают исторические данные, которые представлены в форме таблиц или диаграмм.\n",
    "\n",
    "*Диагностическая аналитика*\n",
    "\n",
    "Диагностическая аналитика направлена на то, чтобы определить причину произошедшего события, используя вопросы, которые фокусируются на причинах этого события. Цель этого типа аналитики — определить, какая информация относится к данному явлению, чтобы дать возможность ответить на вопросы о том, почему это произошло.\n",
    "\n",
    "К таким вопросам относятся:\n",
    "\n",
    "Почему продажи первого предприятия были меньше, чем продажи второго?\n",
    "Почему в службу поддержки поступило больше звонков из восточного региона, чем из западного?\n",
    "Почему увеличилось число повторных госпитализаций пациентов за последние три месяца?\n",
    "\n",
    "Диагностическая аналитика имеет большую значимость, чем дескриптивная, но требует более продвинутого набора навыков. Обычно диагностическая аналитика требует сбора данных из различных источников и хранения их в структуре, которая подвергается детальному анализу и свертыванию.\n",
    "\n",
    "Результаты диагностической аналитики могут быть просмотрены с помощью инструментов интерактивной визуализации, которые позволяют пользователям определять тенденции и шаблоны. Выполнение запросов здесь значительно сложнее, чем в дескриптивной аналитике, и выполняются они на многомерных данных, содержащихся в системах аналитической обработки.\n",
    "\n",
    "*Прогностическая аналитика*\n",
    "\n",
    "Прогностическая аналитика проводится с целью определить результат события, которое может произойти в будущем. С помощью прогностической аналитики информация усиливается смысловым содержанием. Интенсивность и значимость ассоциативных связей формируют основу моделей, которые используются для создания будущих прогнозов на основе прошлых событий.\n",
    "\n",
    "Важно учитывать, что у моделей, которые используются для прогностической аналитики, существуют неявные зависимости от условий, в которых происходили прошлые события. Если лежащие в основе причины изменяются, то и модели прогнозирования должны быть откорректированы.\n",
    "\n",
    "Вопросы обычно формулируются с использованием обоснования «Что, если...», например:\n",
    "\n",
    "Какова вероятность невозвращения клиентом кредита, если пропущен ежемесячный платеж?\n",
    "Каков процент эффективности лечения пациента, если вместо препарата А будет использоваться препарат В?\n",
    "Если клиент приобрел продукты А и В, каковы шансы, что он также купит продукт С?\n",
    "\n",
    "Прогностическая аналитика призвана предсказать исход события, при этом прогнозы делаются на основе шаблонов, тенденций и исключений, найденных в исторических и текущих данных. Это может привести к выявлению как рисков, так и возможностей. Такой вид аналитики предполагает использование больших наборов данных, внутренних и внешних, и различных методов анализа этих данных. Эта аналитика обеспечивает высокую значимость результатов и требует еще более совершенного набора навыков, чем дескриптивная и диагностическая.\n",
    "\n",
    "Как правило, инструменты прогностической аналитики используют лежащие в их основе абстрактные способы решения статистических сложных задач, предоставляя удобные для пользователя внешние интерфейсы.\n",
    "\n",
    "*Прескриптивная аналитика*\n",
    "\n",
    "Прескриптивная аналитика основывается на результатах прогностической аналитики, предписывая меры, которые должны быть предприняты. Акцент делается не только на том, какому предписанному варианту лучше всего следовать, но и почему.\n",
    "\n",
    "Вопросы могут иметь следующий вид:\n",
    "\n",
    "Какой из трех препаратов обеспечивает наилучшие результаты?\n",
    "Когда наилучше время для проведения определенной акции? \n",
    "\n",
    "Прескриптивная аналитика представляет большую значимость, чем любые другие виды аналитики, и, соответственно, требует самого продвинутого набора навыков, а также специализированного программного обеспечения и инструментов.\n",
    "Благодаря ей рассчитываются различные результаты и предлагается оптимальный курс действий для каждого из них. Такая тактика переходит от пояснений к консультациям и может включать в себя моделирование различных сценариев.\n",
    "\n",
    "Этот вид аналитики охватывает внутренние данные одновременно с внешними. Внутренние данные могут включать в себя текущие и исторические данные о продажах, информацию о клиентах, данные о продуктах и бизнес-правила. Внешние же могут содержать данные из социальных сетей, прогнозы погоды и демографические данные, подготовленные правительством."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd0daf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Основные этапы жизненного цикла аналитики больших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95703c05",
   "metadata": {},
   "source": [
    "**Жизненный цикл данных** - это набор процессов в приложении, которые преобразуют необработанные данные в практические знания.\n",
    "\n",
    "Жизненный  цикл  аналитики  больших  данных  можно  разделить  на  следующие  девять  этапов:\n",
    "1. Оценивание ситуации\n",
    "2. Идентификация  данных\n",
    "3. Сбор  и  фильтрация данных\n",
    "4. Извлечение  данных\n",
    "5. Проверка  и  очистка данных\n",
    "6. Агрегирование и  представление  данных\n",
    "7. Анализ  данных\n",
    "8. Визуализация  данных\n",
    "9. Использование результатов  анализа\n",
    "\n",
    "*Оценивание ситуации*\n",
    "\n",
    "Анализ данных связан с формированием цели анализа, определения мотивации.\n",
    "Четкая формулировка цели позволит выбрать основные направления анализа еще до начала  выполнения  реальных  практических  задач  анализа.\n",
    "\n",
    "*Идентификация данных*\n",
    "\n",
    "Этап  идентификации  данных посвящен  определению  наборов  данных,  необходимых  для  аналитических  проектов  и  их  источников.\n",
    " \n",
    " Выявление  наиболее  широкого  спектра  источников  данных  может  увеличить  вероятность  обнаружения  скрытых  закономерностей  и  корреляций.  \n",
    " В  зависимости  от  сферы  деятельности  и  характера  решаемых  бизнес-задач,  требуемые  наборы  данных и  их  источники  могут  быть  внутренними  и/или  внешними для  организации.\n",
    "\n",
    "В  случае  внутренних  наборов  данных,  списки  доступных  наборов  данных  из  внутренних  источников,  таких  как  витрины данных, базы данных,  составляются  и  сравниваются  с  заранее  определенной  спецификацией  набора  данных.\n",
    " \n",
    " При  работе  с  внешними  наборами  данных  составляется  список  возможных  сторонних  поставщиков,  таких  как  витрины данных  и  общедоступные  наборы  данных.  Некоторые формы  внешних  данных  могут  быть  встроены  в  блоги  или другие  типы  веб-сайтов  на  основе  контента,  и  в  этом  случае они,  возможно,  должны  быть  собраны  с  помощью  автоматизированных  инструментов.\n",
    " \n",
    "*Сбор и фильтрация данных*\n",
    "\n",
    "На  этапе  сбора  и  фильтрации  данных данные  собираются  из  всех  источников,  которые были  идентифицированы  на  предыдущем  этапе.  Затем  полученные  данные  подвергаются  автоматизированной  фильтрации  для  удаления  поврежденных  или  таких,  которые  не имеют  особого  значения  для  целей  анализа.\n",
    "\n",
    "В  зависимости  от  типа  источника  данные  могут  поступать как  набор  файлов,  например,  данные,  приобретенные  у  стороннего  поставщика,  или  могут  потребовать  интеграции  API,  например,  с  Twitter.  Во  многих  случаях,  особенно  в  случае  внешних  неструктурированных  данных,  некоторые  или большинство  полученных  данных  могут  быть  нерелевантными  (шумом)  и  могут  быть  отброшены  в  процессе  фильтрации.\n",
    " \n",
    " Данные,  классифицированные  как  «искаженные»,  могут включать  записи  с  отсутствующими  или  бессмысленными \n",
    "значениями  или  недопустимыми  типами  данных.  Данные, отфильтрованные  для  одного  анализа,  могут  быть  значимыми  для  другого  типа  анализа.  Поэтому  рекомендуется сохранить  точную  копию  исходного  набора  данных  перед началом  фильтрации.  Чтобы  свести  к  минимуму  требуемое пространство  для  хранения,  точная  копия  может  быть  сжата.\n",
    "\n",
    "*Извлечение данных*\n",
    "\n",
    "Некоторые  данные,  идентифицированные  как  входные данные  для  анализа,  могут  поступать  в  формате,  несовместимом с алгоритмами обработки данных.  Необходимость  обращаться  к  несопоставимым  типам  данных более  вероятна  при  работе  с  данными  из  внешних  источников.  \n",
    "\n",
    "Этап  жизненного  цикла  извлечения  данных  предназначен  для  извлечения  несопоставимых  данных  и  преобразования  их  в сопоставимый формат,  который  может  использовать  в \n",
    "целях  анализа  данных.\n",
    " \n",
    "Необходимая  степень  извлечения  и  преобразования  зависят  от типов  аналитики.  Например,  извлечение  обязательных  полей  из  текстовых данных  с  разделителями,  таких  как  файлы  журнала  веб-сервера,  может  не  понадобиться,  если  базовые  решения  для  больших  данных  уже  могут  напрямую  обрабатывать  эти  файлы.\n",
    "\n",
    "Аналогично,  извлечение  текста  для  аналитики  текста,  который  требует  сканирования  всех  документов,  упрощается, если  базовое  решение  для  больших  данных  может  напрямую читать  документ  в  его  собственном  формате.\n",
    "\n",
    "*Проверка и очистка данных*\n",
    "\n",
    "Неправильные  данные  могут  искажать  и  фальсифицировать результаты  анализа.  В  отличие  от  традиционных  корпоративных  данных,  где  структура  данных  заранее  определена и  данные  предварительно  проверены,  данные  вводимые  в анализ  больших  данных  могут  быть  неструктурированными,  без  каких-либо  указаний  на достоверность.  Эта  сложность  также  может  затруднить  получение  набора  подходящих  ограничений  проверки.\n",
    " \n",
    "Этап  проверки  и  очистки  данных предназначен  для  создания  зачастую  сложных  правил  проверки  и  удаления  любых  известных  недопустимых  данных.\n",
    "\n",
    "*Агрегирование и представление данных*\n",
    "\n",
    "Данные  могут  быть  распределены  по  нескольким  наборам данных,  требуя  объединения  наборов  данных  через  общие  поля,  например  дату  или  идентификатор  (ID).  \n",
    "\n",
    "Этап  агрегирования  и  представления  данных предназначен  для  интеграции  нескольких  наборов  данных  вместе  для  достижения  унифицированного  представления.\n",
    "\n",
    "\n",
    "*Анализ данных*\n",
    "\n",
    "Этап  анализа  данных  посвящен выполнению  фактической  задачи  анализа,  которая  обычно включает  в  себя  один  или  несколько  типов  аналитики.  Этот этап  может  быть  итеративным  по  своей  природе,  особенно если  анализ  данных  является  разведывательным  —  в  этом случае  анализ  повторяется  до  тех  пор,  пока  не  будет  обнаружен  соответствующий  шаблон  или  корреляция.  \n",
    "\n",
    " В  зависимости  от  типа  требуемого  аналитического  результата  этот  этап  может  быть  таким  же  простым,  как  запрос  к набору  данных,  чтобы  вычислить  агрегирование  для  сравнения.  С  другой  стороны,  это  может  быть  столь  же  сложным, как  комбинирование  интеллектуального  анализа  данных  и сложных  методов статистического  анализа  для  обнаружения  закономерностей  и  аномалий,  или  для  создания  статистической  или  математической  модели,  описывающей  взаимосвязи  между  переменными.\n",
    " \n",
    " Анализ  данных  может  быть  классифицирован  как  *подтверждающий  или  разведывательный  анализ*,  последний  из  которых  связан  с  data  mining. \n",
    " \n",
    " *Подтверждающий  анализ*  данных  является  дедуктивным подходом,  при  котором  причина  исследуемого  явления предлагается  заранее.  Предлагаемая  причина  или  предположение  называется  гипотезой.  Затем  данные  анализируются  для  того,  чтобы  подтвердить  или  опровергнуть  гипотезу  и  дать  окончательные  ответы  на  конкретные  вопросы.\n",
    " \n",
    "*Разведывательный  анализ*  данных  представляет  собой  индуктивный  подход,  который  тесно  связан  с  data  mining.  Ни одна  из  гипотез  или  предположений  не  генерируются  заранее.  Вместо  этого  данные  анализируются  для  развития  понимания  причины  этого  явления.  Хотя анализ  может  и  не  давать  окончательных  ответов,  этот  метод  позволяет сформировать  направление,  которое  может  способствовать  обнаружению  закономерностей  или  аномалий.\n",
    "\n",
    "*Визуализация данных*\n",
    "\n",
    "Способность  анализировать  огромные  объемы  данных  и находить  полезные  идеи  не  имеет  большого  значения,  если единственными,  кто  может  интерпретировать  результаты, являются  аналитики.\n",
    "\n",
    "Этап  визуализации  данных посвящен  использованию  методов  визуализации  данных и  инструментам  графического  представления  результатов анализа  для  их  эффективной  интерпретации  пользователями.\n",
    "\n",
    "*Использование результатов анализа*\n",
    "\n",
    "После  получения  результатов  анализа,  предоставляемых пользователям  для  поддержки  принятия  решений,  они могут располагаться на  информационных  панелях.  Этап  использования  результатов  анализа посвящен  определению  того,  как  и  где \n",
    "обрабатываемые  аналитические  данные  могут  быть  в  дальнейшем  использованы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a1e95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Основные методы анализа больших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123184a",
   "metadata": {},
   "source": [
    "Анализ  больших  данных  сочетает традиционные  методы  статистического  анализа  данных  с  вычислительными  методами.\n",
    "\n",
    "Принято выделять общие и частные методы анализа больших данных. \n",
    "\n",
    "Среди общих методов следует выделить: \n",
    "- количественный  анализ\n",
    "- качественный  анализ\n",
    "- Data  Mining  (интеллектуальный  анализ  данных)\n",
    "\n",
    "Внутри Data  Mining часто говорят про следующие методы:\n",
    " - статистический  анализ\n",
    " - машинное  обучение\n",
    " - семантический  анализ\n",
    " - визуальный  анализ\n",
    "\n",
    "*Количественный  анализ*  —  это  метод  анализа  данных,  который  фокусируется  на  определении  количественных  закономерностей  и  корреляций,  найденных  в  данных.  Основанный на  статистических  методах,  этот  метод  предполагает  анализ  большого  количества  наблюдений  из  набора  данных.  Поскольку  размер  выборки  большой,  результаты  могут  применяться  обобщенно  ко  всему  набору  данных. \n",
    "\n",
    "Результаты  количественного  анализа  носят  абсолютный характер  и  поэтому  могут  использоваться  для  численных сравнений.  Например,  количественный  анализ  по  продажам мороженого  может  обнаружить,  что  увеличение  температуры  на  5  градусов  увеличивает  продажи  мороженого  на  15%.\n",
    "\n",
    "*Качественный  анализ*  —  это  метод  анализа  данных,  который  фокусируется  на  описании  различных  качеств  данных с  использованием  слов.  \n",
    "\n",
    "Он  предполагает  анализ  меньшей  выборки,  но  более  основательнее,  по  сравнению  с  количественным  анализом  данных.  Такие  результаты  анализа  не могут  быть  обобщены  на  весь  набор  данных  из-за  небольшого  размера  выборки.  Их  также  нельзя  численно  измерить или  использовать  для  числовых  сравнений.  Например,  качественный  анализ  по  продажам  мороженого  может  показать,  что  показатели  продаж  в  мае  были  не  такими  высокими,  как  в  июне.  Результаты  анализа  указывают  только  на  то, что  цифры  «не  так  высоки,  как»,  и  не  дают  количественной разницы.  Результатом  качественного  анализа  является  описание  отношения  с  использованием  слов.\n",
    "\n",
    "*Data  Mining*\n",
    "\n",
    " Data  Mining  (интеллектуальный  анализ  данных),  известен  также  как  обнаружение  данных,  представляет  собой  специализированную  форму  анализа  данных,  предназначенную для  больших  наборов  данных.  В  связи  с  анализом  больших данных,  Data  Mining  обычно  относится  к  автоматизированным,  основанным  на  программном  обеспечении  методам, которые  просеивают  массивные  наборы  данных  для  выявления  закономерностей  и  тенденций.\n",
    " \n",
    " В  частности,  это  предполагает  извлечение  скрытых  или  неизвестных  шаблонов  в  данных  с  целью  идентификации ранее  неизвестных  закономерностей. Data  Mining  является  основой  для  прогностической аналитики  и  Business Intelligence  (BI).\n",
    " \n",
    "*Статистический  анализ*\n",
    "\n",
    " Статистический  анализ  использует  статистические  методы, основанные  на  теории вероятностей и математической статистики  в  качестве  средства  для  анализа  данных.  Статистический  анализ  чаще  всего является  количественным,  но  может  быть  и  качественным. \n",
    "\n",
    "Этот  тип  анализа  обычно  используется  для  описания  наборов  данных  посредством  итогового  обобщения,  например, предоставление  среднего  значения.\n",
    " Среди важных методов можно указать  следующие  виды  статистического  анализа:\n",
    " * проверка статистических гипотез\n",
    " * корреляционный анализ\n",
    " * регрессионный анализ\n",
    "\n",
    "*Машинное обучение*\n",
    "\n",
    "Люди  хорошо  разбираются  в  шаблонах  и  отношениях  внутри  данных.  К  сожалению,  мы  не  можем  обработать  большие объемы  данных  очень  быстро.  Машины,  с  другой  стороны, очень  искусны  в  быстрой  обработке больших  объемов  данных,  но  только  тогда,  когда знают  как.\n",
    "\n",
    "Если  знания  человека  сочетать  со  скоростью  обработки  машины,  то  последние  смогут  обрабатывать  большие  объемы данных,  без  особого  вмешательства  человека.  Это  и  является основной  концепцией  машинного обучения.\n",
    "\n",
    "В  Data  Mining  можно выделить следующие важные  методы  машинного  обучения:\n",
    " * Классификация\n",
    " * Кластеризация\n",
    " * Обнаружение  выбросов\n",
    " * Фильтрация\n",
    "\n",
    "*Классификация*  —  это  метод  обучения  с  учителем,  при  котором  данные  классифицируются  на  релевантные,  заранее исследованные  категории.  \n",
    "Данный метод состоит  из  двух  этапов:\n",
    " 1. Система  получает  обучающие  данные,  которые  уже  классифицированы  или  промаркированы,  для  возможности развития  понимания  различных  категорий.\n",
    " 2. Система  получает  неизвестные,  но  аналогичные  данные для  классификации,  и  на  основании  понимания,  которое она  получила  из  обучающих  данных,  алгоритм  классифицирует  немаркированные  данные.\n",
    " \n",
    " Примером  применения  этого  метода  является  фильтрация спама  электронной  почты.  \n",
    " \n",
    " Классификация  может  проводиться  по  двум  или  более  категориям.\n",
    " \n",
    " Примеры вопросов, которые можно решать с использованием классификации:\n",
    " \n",
    " * Следует  ли  принять  или  отклонить  заявку  претендента на  выдачу  кредитной  карты  на  основании  других  принятых или  отклоненных  заявок?\n",
    " * Является  ли  томат  фруктом  или  овощем,  основываясь  на известных  примерах  фруктов  и  овощей?\n",
    " * Результаты  клинических  испытаний  для  пациентов  свидетельствуют  об  угрозе  сердечного  приступа?\n",
    " \n",
    " Для классификации используют целый арсенал математических подходов (методов, алгоритмов): опорные вектора, градиентный бустинг, деревья решений, нейронные сети и т.д.\n",
    " \n",
    "*Кластеризация*  —  это  метод  обучения  без  учителя,  при  котором  данные  делятся  на  разные  группы,  так  что  данные  в  каждой  группе  имеют  схожие  свойства.  Не  требуется  никакого предварительного  изучения  требуемых  категорий.  Вместо этого  категории  генерируются  неявно  на  основе  группирования  данных.  Способ  группирования  данных  зависит  от типа  используемого  алгоритма.  Каждый  алгоритм  использует  различную  технику  для  определения  кластеров.\n",
    " \n",
    " Кластеризация  обычно  используется  в  Data  Mining  для  получения  представления  о  свойствах  заданного  набора  данных. После  разработки  такого  понимания  классификация  может использоваться  для  более  точного  прогнозирования  подобных,  но  новых  или  ненаблюдаемых  данных.\n",
    "\n",
    "Кластеризация  может  применяться  для  категоризации  неизвестных  документов  и  персонализированных  маркетинговых  кампаний,  группируя  клиентов  со  схожим  поведением.\n",
    "\n",
    "Вопросы, решаемые в рамках кластеризации,   могут  включать  в  себя:\n",
    " * Сколько  существует  различных  видов  деревьев,  основываясь на  сходстве  между  деревьями?\n",
    " * Сколько  существует  групп  клиентов,  основываясь  на  истории  аналогичных  покупок?\n",
    " * Какие  различные  группы  вирусов,  основываясь  на  их  характеристиках?\n",
    " \n",
    " Для кластеризации также используют целый ряд математических методов и алгоритмов: k-means, иерархическая кластеризация, генетические алгоритмы, нейронные сети и т.д.\n",
    " \n",
    " *Обнаружение  выбросов*  —  это  процесс  поиска  данных,  которые  существенно  отличаются  от  других  данных  в  заданном наборе  данных  или  несовместимы  с  ними.  Этот  метод  машинного  обучения  используется  для  выявления  аномалий, патологий  и  отклонений,  которые  либо следует исключить из рассмотрения при анализе или наоборот, обратить на них пристальное внимание при анализе возможных рисков.\n",
    " \n",
    " Обнаружение  выбросов  тесно  связано  с  концепцией  классификации  и  кластеризации,  хотя  алгоритмы  и  сосредоточены на  поиске  аномальных  значений.  Процесс  может  основываться  либо  на  контролируемом,  либо  на  неконтролируемом обучении.  \n",
    " \n",
    " Приложения  для  обнаружения  выбросов  включают  обнаружение  мошенничества,  медицинскую  диагностику,  анализ  сетевых  данных  и  анализ  данных  датчиков.\n",
    " \n",
    " Примеры  вопросов  могут  включать  в  себя  следующее:\n",
    " * Является  ли  спортсмен  тем,  кто  использовал  допинговые препараты?\n",
    " * Имеются  ли  неправильно  идентифицированные  фрукты  и овощи  в  учебном  наборе  данных,  который используется  для задачи  классификации?\n",
    " * Существует  ли  особый  штамм  вируса,  который  не  реагирует  на  лекарства?\n",
    " \n",
    " *Фильтрация* - это  автоматизированный  процесс  поиска  релевантных  элементов  из  совокупности  всех  элементов.  Элементы  могут  быть  отфильтрованы  либо  на  основе  собственного  поведения  пользователя,  либо  путем  сопоставления поведения  нескольких  пользователей.  \n",
    " \n",
    " Фильтрация  обычно применяется  с  помощью  следующих  двух  подходов:\n",
    "* коллаборативной  фильтрации\n",
    "* фильтрации  на  основе  контента\n",
    " \n",
    " Широко  распространённым  средством  для  осуществления фильтрации,  является  использование  рекомендационных \n",
    "систем.  \n",
    "\n",
    "Коллаборативная  фильтрация  — это один из методов построения прогнозов (рекомендаций) в рекомендательных системах, использующий известные предпочтения (оценки) группы пользователей для прогнозирования неизвестных предпочтений другого пользователя.\n",
    "\n",
    "Фильтрация  на  основе  контента  —  это  метод  фильтрации элементов,  сфокусированный  на  сходстве  между  пользователями  и  элементами.  Профиль  пользователя  создается  на основе  предыдущего  поведения  пользователя,  например, его  предпочтений,  оценок  и  истории  покупок.  Сходства,  выявленные  между  профилем  пользователя  и  атрибутами  различных  элементов,  приводит  к  элементам,  которые  фильтруются  для  пользователя.  В  противовес  коллаборативной фильтрации,  фильтрация  на  основе  контента  предназначена  исключительно  для  индивидуальных  предпочтений пользователя  и  не  требует  данных  о  других  пользователях. Данный метод, например, используется для реализации контент-фильтра - устройство или программное обеспечение для фильтрации сайтов по их содержимому, не позволяющее получить доступ к определённым сайтам или услугам сети Интернет. Система позволяет блокировать веб-сайты с содержимым, не предназначенным для просмотра.\n",
    "\n",
    "Примеры  вопросов  могут  включать  в  себя:\n",
    " * Как  можно  отображать  только  те  новостные  статьи,  которые  интересуют  пользователя?\n",
    " * Какие  места  для  отдыха  можно  порекомендовать,  основываясь  на  истории  путешествий  отдыхающего?\n",
    " * Каких  других  новых  пользователей  можно  предложить  в  качестве  друзей  на  основе  текущего  профиля  пользователя?\n",
    "\n",
    "*Семантический анализ (Text Mining)*\n",
    "\n",
    "Семантический анализ  представляет  собой  практический  метод  извлечения значимой  информации  из  текстовых  и  речевых  данных.\n",
    "\n",
    "Среди основные методов можно указать:\n",
    "\n",
    "* распознавание голоса\n",
    "* автоматизированное формирование резюме по тексту\n",
    "* тематическая близость текстов\n",
    "* распознавание эмоциональной окраски\n",
    "\n",
    "*Визуальный анализ* является  формой  анализа  данных,  которая  содержит  графическое  представление  данных  для  обеспечения  или  улучшения  их  визуального  восприятия.  Основываясь  на  предположении,  что  людям  проще  и  быстрее  понять  и  сделать  выводы  из  графиков,  чем  из  текстов,  визуальный  анализ  действует  как инструмент  обнаружения  знаний  в  области  больших  данных.\n",
    " \n",
    " Цель  заключается  в  использовании  графических  представлений  для  более  глубокого  понимания  анализируемых  данных.  В  частности,  это  помогает  выявлять  и  подчеркивать скрытые  закономерности,  корреляции  и аномалии.  Визуальный  анализ  также  непосредственно  связан  с  пробным анализом  данных,  поскольку  он  подходит  с разных  сторон  к формулированию  вопросов.\n",
    " \n",
    " Среди методов визуального анализа можно указать:\n",
    " * Цветовые  карты\n",
    " * Временные  ряды\n",
    " * Сетевые  графики\n",
    " * Сопоставление  пространственных  данных\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c4649-c1e0-47ee-9daa-5ae3c2551438",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Обзор программных средств анализа больших данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6b086-cbf1-48e7-ac68-fcb0251973dd",
   "metadata": {},
   "source": [
    "При обзоре программных средств следует говорить про два взаимосвязанных, но самостоятельных направления:\n",
    "1. программные средства создания и содержания инфраструктуры больших данных;\n",
    "2. программные средсва анализа больших данных.\n",
    "\n",
    "В первом направлении нужно выделить фреймворк Hadoop (https://hadoop.apache.org/) для разработки и выполнения распределённых программ, работающих на кластерах из сотен и тысяч узлов. \n",
    "\n",
    "Все началось в 2004 году, когда компания Google опубликовала статью, посвященную процессу MapReduce. Каркас MapReduce использует модель параллельной обработки\n",
    "очень большого объема данных. В рамках MapReduce запросы разделяются и\n",
    "распределяются по параллельным узлам, при этом они обрабатываются\n",
    "параллельно (этап распределения (Мар)). Затем осуществляется сбор и\n",
    "доставка результатов (этап преобразования (Reduce)). \n",
    "\n",
    "\n",
    "Hadoop на данный момент является «де-факто» стандартом создания и обслуживания инфраструктры больших данных. Hadoop представляет собой фреймворк, на основе которого\n",
    "разрабатываются приложения для анализа и визуализации больших данных.\n",
    "Хранение данных в данном фреймворке осуществяляется с помощью\n",
    "специальной распределённой файловой системы HDFS (Hadoop Distributed\n",
    "File System), которая лежит в основе Hadoop и позволяет хранить и\n",
    "предоставлять доступ к данным сразу на нескольких узлах кластера. Таким\n",
    "образом, если один или несколько узлов кластера выходят из строя, то риск\n",
    "потери информации сводится к минимуму и кластер продолжает работу в\n",
    "штатном режиме.\n",
    "\n",
    "В рамках второго направления существует огромное количество различных инструментов. Остановимся на ключевых из них:\n",
    "\n",
    "**WEKA**\n",
    "\n",
    "Weka ( https://www.cs.waikato.ac.nz/~ml/weka/ ), программное обеспечение с открытым исходным кодом, представляет собой набор алгоритмов машинного обучения для задач интеллектуального анализа данных. Алгоритмы могут быть применены непосредственно к набору данных или вызваны из вашего собственного Java-кода. Он также хорошо подходит для разработки новых схем машинного обучения, поскольку полностью реализован на языке программирования Java, а также поддерживает несколько стандартных задач интеллектуального анализа данных. Weka с ее графическим интерфейсом, обеспечивает самый простой переход в мир Data Science. Для пользователей с опытом программирования на Java есть возможность встраивать в библиотеку свой собственный код.\n",
    "\n",
    "<img src=\"ris2.jpg\">\n",
    "\n",
    "**Язык общего назначения Python (https://www.python.org/)**\n",
    "\n",
    "Основные преимущества: \n",
    " - Простой, но выразительный синтаксис.\n",
    " - Богатый выбор библиотек. И речь не только о библиотеках алгоритмов машинного обучения — на Python разрабатывают облачные хранилища, стриминговые сервисы.\n",
    " Ниже перечислены некоторые из библиотек:\n",
    "   - Pandas — библиотека для манипулирования данными с огромными возможностями. Позволяет очень быстро провести исследование новых данных, протестировать гипотезы, получить отчёт. Одно из главных преимуществ Python.\n",
    "   - Scikit-learn — большая библиотека алгоритмов машинного обучения и обработки данных. \n",
    "   - Keras и PyTorch — библиотеки, используемые для обучения глубоких нейронных сетей. Подходят для задач, связанных с изображениями, аудио и видео файлами.\n",
    "   - IPython Notebook — рассказывая о Python нельзя не упомянуть о нём. Стандартная среда разработки не совсем подходит data scientist’у в процессе исследования данных. Есть потребность в таком формате, который позволил бы, например, запустить затратный алгоритм, а когда он завершится — поиграть немного с результатами, исследовать их и построить графики. Здесь на помощь и приходит формат ноутбука. Это графический интерфейс, который открывается в обычном браузере и представляет из себя последовательность ячеек, где можно писать и исполнять код, используя при этом общую память для хранения данных.\n",
    " - Высокая культура документации. Сам Python прекрасно документирован, и обычно библиотеки на нём продолжают эту традицию.\n",
    "    \n",
    "**Язык статистических вычислений R (https://www.r-project.org/)** \n",
    "\n",
    "В 2020 году язык R остаётся одним из самых популярных для Data Science и статистики, стабильно завоёвывая всё большую долю просмотров в соответствующих разделах StackOverflow. При этом, со значительным перевесом лидируют вопросы академического характера: в первую очередь, R — это язык с богатым набором библиотек по машинному обучению и статистике, что особенно важно в исследовательских целях.\n",
    "\n",
    "Основные преимущества:\n",
    " - Огромное количество библиотек статистических методов. R особенно популярен в академической среде, что и приводит к тому, что часто новые методы впервые имплементируются именно на нём.\n",
    " - Достаточно удобная проприетарная среда разработки RStudio, с которой будет легко разобраться.\n",
    " - Необычный синтаксис, заточенный под нужды статистики. \n",
    " - Нативная поддержка векторных вычислений. \n",
    " \n",
    "**Anaconda (https://www.anaconda.com/)**\n",
    " \n",
    "Anaconda — дистрибутив языков программирования Python и R, включающий набор популярных свободных библиотек, объединённых проблематиками науки о данных и машинного обучения. Основная цель — поставка единым согласованным комплектом наиболее востребованных соответствующим кругом пользователей тематических модулей (таких как NumPy, SciPy, Astropy и других) с разрешением возникающих зависимостей и конфликтов.\n",
    "\n",
    "<img src=\"ris3.png\">\n",
    " \n",
    "\n",
    "**Сравнение Python и R**\n",
    "\n",
    "Оба языка обладают своими достоинствами и недостатками. Подойти может любой из них, всё зависит от ваших задач. Вот некоторые моменты, которые могут помочь с выбором:\n",
    "\n",
    "- При программировании  Python гораздо более привычен.\n",
    " - Python больше приближен к продакшену и чаще применяется в коммерческих проектах. В то же время, в академических кругах большей популярностью пользуется R.\n",
    "- Хотите ли вы расширить кругозор в методах машинного обучения? Или вам достаточно будет ознакомиться с несколькими наиболее популярными методами и больше времени посвятить, например, алгоритмам обработки больших данных? В первом случае вам однозначно нужен R, во втором — больше возможностей вы найдёте в Python.\n",
    " - Хотите ли вы заниматься внедрением своих разработок, и программировать что-либо? Если да, то Python вам подойдёт лучше, но скорее всего понадобится и что-то ещё (например Java, Scala или C++)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
