\documentclass[12pt, pdf, hyperref={unicode},handout]{beamer}

\mode<presentation>
{
  \usetheme{Madrid}       % or try default, Darmstadt, Warsaw, ... Madrid
  \usecolortheme{default} % or try albatross, beaver, crane, ...default
  \usefonttheme{serif}    % or try default, structurebold, ... serif
  \usefonttheme{professionalfonts}
  \setbeamertemplate{navigation symbols}{}
% \setbeamertemplate{caption}[numbered]
} 

\usepackage[english,russian]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{hyperref}
\graphicspath{{image/}}
\definecolor{links}{HTML}{2A1B81}
\hypersetup{colorlinks,linkcolor=,urlcolor=links}
\usepackage{listings}
\usepackage{concmath}
\usepackage{ragged2e}
\renewcommand{\raggedright}{\leftskip=0pt \rightskip=0pt plus 0cm}
\usepackage[orientation=landscape,size=A4, scale=4]{beamerposter}
\usepackage{enumerate}
\usepackage[T2A]{fontenc}
\usepackage{subfigure}
\usepackage{float}
\usepackage{setspace}
\usepackage{array,longtable}

\lstset{language=Python}


\newtheorem{hyp}{Гипотеза}
\newtheorem{theor}{Теорема}
\newtheorem{dfn}{Определение}
\newtheorem{resume}{Следствие}
\newtheorem{exmpl}{Пример}


% Here's where the presentation starts, with the info for the title slide
\title[Лекция 1]{\Huge{Формальные языки и грамматики}}
\author[\textcopyright   Артамонов Ю.Н.]{}
\institute[]{}
\date{}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

% These three lines create an automatically generated table of contents.
\begin{frame}{Содержание}
  \tableofcontents
\end{frame}

\section{Вводные замечания}


\begin{frame}{Цели и задачи курса}
  \begin{block}

    \small{
      Вы уже изучили или получили представление о многих популярных языках программирования: С, С++, Python, Common Lisp, Java... А что нужно, чтобы создать свой язык программирования? Каким минимальным набором элементов необходимо обладать, чтобы получить полноценный язык программирования? Какое аппаратное устройство нужно использовать, чтобы реализовать этот язык программирования, как должно работать это устройство? Как строить наиболее оптимальный код на придуманном языке программирования, учитывая архитектуру аппаратного устройства,на котором происходит программирование? На все эти вопросы в идеале должен отвечать курс <<Основы теории языков программирования и методы трансляции>>.

      Нужно однако сказать, что практика пока не соответствует идеалу. Во-первых, необходимо отметить, что возможный язык программирования и техническая платформа (аппаратное устройство) очень тесно взаимосвязаны. Все, что на сегодняшний день хорошо разработано и детально исследовано, касается традиционной архитектуры  - архитектуры фон-Неймана. Во-вторых, далеко не для всех формальных языков разработаны эффективные алгоритмы трансляции программ, написанных на этих языках, в инструкции, понятные конечному аппаратному устройству  архитертуры фон-Неймана.


}

  \end{block}
  
\end{frame}

\begin{frame}{Исторические предпосылки}
  \begin{block}

    \small{
Анализируя принципы и возможности построения абстрактных вычислительных устройств (машин), ученые последовательно наращивали их возможности. В 1940-х и 1950-х годах немало исследователей занимались изучением простейших машин, которые сегодня называются “конечными автоматами”. Такие автоматы вначале были предложены в качестве модели функционирования человеческого мозга. Однако вскоре они оказались весьма полезными для множества других целей, решаемых современными трансляторами. В 1930-е годы, задолго до появления компьютеров, А. Тьюринг исследовал абстрактную машину, которая, по крайней мере в области вычислений, обладала всеми возможностями современных вычислительных машин. Целью Тьюринга было точно
описать границу между тем, что вычислительная машина может делать, и тем, чего она не может. Полученные им результаты применимы не только к абстрактным машинам Тьюринга, но и к реальным современным компьютерам.

В конце 1950-х лингвист Н. Хомский занялся изучением формальных “грамматик”. Не будучи машинами в точном смысле слова, грамматики, тем не менее, тесно связаны с абстрактными автоматами и служат основой некоторых важнейших составляющих программного обеспечения, в частности, компонентов компиляторов-трансляторов.

}

  \end{block}
  
\end{frame}

\begin{frame}{Исторические предпосылки}
  \begin{block}

    \small{
В 1969 году С. Кук развил результаты Тьюринга о вычислимости и невычислимости.
Ему удалось разделить задачи на те, которые могут быть эффективно решены вычислительной машиной, и те, которые, в принципе, могут быть решены, но требуют для этого так много машинного времени, что компьютер оказывается бесполезным для решения практически всех экземпляров задачи, за исключением небольших.

Задачи последнего класса называют “трудно разрешимыми” (“труднорешаемыми”) или “NP-трудными”.
Даже при экспоненциальном росте быстродействия вычислительных машин (“закон Мура”) весьма маловероятно, что нам удастся достигнуть значительных успехов в решении
задач этого класса.

Все эти теоретические построения непосредственно связаны с тем, чем занимаются
ученые в области информатики сегодня. Некоторые из введенных понятий, такие, например, как конечные автоматы и некоторые типы формальных грамматик, используются при проектировании и создании важных компонентов программного обеспечения.

Другие понятия, например, машина Тьюринга, помогают нам уяснить принципиальные возможности программного обеспечения.
}

  \end{block}
  
\end{frame}

\section{Основные понятия о трансляторах}
\begin{frame}{Определение транслятора}
  \begin{block}

    \small{
      \textit{Предположим, что имеется некоторый язык  $A$, понятный субъекту (устройству) $S_A$, требуется перевести его в язык $B$, понятный субъекту (устройству) $S_B$. Такой процесс называется \textbf{трансляцией}, а устройство (<<черный ящик>>), выполняющее это преобразование называется \textbf{транслятором}.}

      Из данного определения видно, что возможна широкая трактовка процесса трансляции:
      \begin{itemize}
      \item{Процесс перевода китайского текста на русский - транляция, переводчик - транслятор.}
      \item{Процесс перевода программы с языка программирования С на язык программирования Python - трансляция, программа, выполняющая такое преобразование - транслятор.}
        \item{Процесс перевода программы с языка программирования С на машинный язык - трансляция, программа, которая выполняет такую трансляцию, тоже транслятор, который чаще называют \textbf{компилятором}.}
        \end{itemize}
      }
      Входной язык $A$ называется \textit{исходным}, входная программа на этом языке - \textit{исходным кодом}. Язык $B$, на который осуществляется трансляция, называется \textit{объектным языком}, результат трансляции - \textit{объектным кодом}. Устройство, на котором впоследствии оттранслированная программа будет запущена, называется \textit{целевой машиной}.

  \end{block}
  
\end{frame}

\begin{frame}{Виды трансляторов}
  \begin{block}

    \small{
      Как было показано, трансляторы могут выполнять разные задачи. При трансляции языков программирования это замечание также остается верным.

      \textit{Если задачей трансляции является перевод в язык низкого уровня, например, машинный язык или язык ассемблера, то такой транслятор называется \textbf{компилятором}.}

      \textit{Если задача трансляции состоит в непосредственном выполнении транслятором операторов исходного кода, то такой транслятор называется \textbf{интерпретатором}.}

      В настоящее время часто используют \textbf{смешанные схемы}, когда код частично компилируется, частично интерпретируется: трансляция их выполняется как компиляция исходного кода на некоторый промежуточный код (пи-код, байт-код и т.д.) с последующей интерпретацией полученного промежуточного пи-кода. Фактически прогон такой программы есть интерпретация ее пи-кода. Типичными языками, для которых это оказывается справедливо - Python, Java.

      \textit{В некоторых случаях стоит задача трансляции, при которой выходом является программа на языке высокого уровня, а входом - программа, написанная на некотором расширении этого языка. Такие трансляторы называются \textbf{препроцессорами}. Например, препроцессор обработки макросов.}
      }

  \end{block}
  
\end{frame}

\section{Формальные языки}

\begin{frame}{Определение формальных языков}
  \begin{block}

    \small{
      Наши определения всевозможных трансляторов остаются неполными, так как совершенно неясно, что понимается под исходным языком, объектным кодом - каким правилам и ограничениям они должны удовлетворять, как проверить, является ли некоторая комбинация символов  предложением данного языка. Чтобы ответить на эти вопросы, необходимо строго формально ввести понятие языка, а также рассмотреть правила его задания.

      Здесь мы сразу упростим себе жизнь и будем рассматривать очень простые языки, которые легко задать небольшим конечным перечнем простых правил. Ровно такие простые языки мы и будем называть формальными языками, подчеркивая их формальный характер, т.е., как правило, в обычном понимании такие языки не обладают никаким смыслом.

      На самом деле вопрос смысла или \textit{семантики} языка - это тоже очень сложный вопрос. Рассматривая формальные языки правильнее сказать, что у них очень простая семантика - примитивный смысл. Итак начнем с ряда формальных определений.
      }

  \end{block}
  
\end{frame}

\begin{frame}{Определение формальных языков}
  \begin{block}

    \small{
      \begin{dfn}
        \textbf{Алфавитом} называется конечное непустое множество. Его элементы называются \textbf{символами}.
      \end{dfn}
      \begin{dfn}
        \textbf{Словом} в алфавите $\Sigma$ называется конечная последовательность элементов из $\Sigma$.
      \end{dfn}
      \begin{exmpl}
        Рассмотрим алфавит $\Sigma=\{a,b,c\}$. Тогда $baaa$ является словом в алфавите $\Sigma$.
      \end{exmpl}
      \begin{dfn}
        Слово, не содержащее ни одного символа (то есть последовательность длины 0), называется \textbf{пустым словом} и обозначается $\epsilon$.
      \end{dfn}
      }

  \end{block}
  
\end{frame}

\begin{frame}{Определение формальных языков}
  \begin{block}

    \small{
      \begin{dfn}
        \textbf{Длина} слова $\omega$, обозначаемая $|\omega|$, есть число символов в $\omega$, причем каждый символ считается столько раз, сколько он встречается в $\omega$.
      \end{dfn}
      \begin{exmpl}
        $|baaa|=4, |\epsilon|=0$.
      \end{exmpl}
      \begin{dfn}
        Если $x,y$ два слова в алфавите $\Sigma$, то слово $xy$ (результат приписывания слова $y$ в конец слова $x$) называется \textbf{конкатенацией} слов $x, y$. Если $y=x$, то $xy=xx$ обозначают $x^2$ и т.д. $x^n=xxx\ldots x $($n$ раз), $x^0=\epsilon$.
      \end{dfn}
      \begin{exmpl}
        $ba^3=baaa, (ba)^3=bababa$
      \end{exmpl}
      }

  \end{block}
  
\end{frame}

\begin{frame}{Определение формальных языков}
  \begin{block}

    \small{
      \begin{dfn}
        Множество всех слов в алфавите $\Sigma$ обозначается $\Sigma^*$. Множество всех непустых слов в алфавите $\Sigma$ обозначается $\Sigma^+$.
      \end{dfn}
      \begin{exmpl}
        Если $\Sigma=\{a\}$, то $\Sigma^*=\{\epsilon,a,aa,aaa,\ldots\}, \Sigma^+=\{a,aa,aaa,\ldots\}$
      \end{exmpl}
      Данные определения позволяют весьма просто ввести определение формального языка, как некоторого подмножества над некоторым алфавитом:
      \begin{dfn}
        Если $L\subseteq \Sigma^*$, то $L$ называется \textbf{формальным языком} над алфавитом $\Sigma$.
      \end{dfn}
      Поскольку формальный язык является множеством, можно рассматривать операции объединения, пересечения, разности языков, заданных над одним и тем же алфавитом.
      }

  \end{block}
  
\end{frame}

\begin{frame}{Определение формальных языков}
  \begin{block}

    \small{
      Над языками также вводят и ряд специфических операций.
\begin{dfn}
        Пусть $L_1, L_2\subseteq \Sigma^*$, тогда $L_1\cdot L_2=\{xy:x\in L_1, y\in L_2\}$ называется конкатенацией языков $L_1,L_2$.
      \end{dfn}
      \begin{exmpl}
        $L_1=\{a,abb\}, L_2=\{bbc,c\}$, тогда $L_1\cdot L_2=\{abbc, ac, abbbbc\}$
      \end{exmpl}
      \begin{dfn}
        Пусть $L\subseteq \Sigma^*$. Тогда $L^0=\{\epsilon\}$, $L^n=L\cdot L\cdot\ldots \cdot L $( $n$ раз).
      \end{dfn}
      \begin{exmpl}
        Пусть $L=\{a^kba^l:0<k<l\}$, тогда $L^2=\{a^kba^lba^m:0<k<l-1,m>1\}$
      \end{exmpl}
      \begin{dfn}
        \textbf{Итерацией} языка $L$ (обозначается $L^*$) называется язык $\cup_{n\in\mathbb{N}}L^n$ (эта операция также называется звездочкой Клини).
      \end{dfn}
      }

  \end{block}
  
\end{frame}

\begin{frame}{Примеры формальных языков}
  \begin{block}

    \small{
      \begin{enumerate}
      \item{$\Sigma=\{a,b\}, L_1=\{a^nb^n:n\geq 0\}$ - это бесконечное множество таких цепочек, которые начинаются символами $a$, заканчиваются символами $b$, причем количество символов $a,b$ одинаково.}
      \item{$\Sigma=\{a,b\}, L_2=\{\alpha:\text{в цепочке $\alpha$ количество вхождений a и b равны}\}$. Например, $ababab\in L_2, aab\not \in L_2$.}
      \item{$\Sigma=\{(,)\}, L_3 - \text{множество правильных скобочных выражений}$. Например, $(())()\in L_3, ))(()\not \in L_3$.}
      \item{$\Sigma=\{a,b,c\}, L_4=\{\omega c \omega : \omega\in \{a,b\}^*\}$ - две идентичные цепочки из символов $a,b$ слева и справа от символа $c$.}
        \item{$\Sigma=\{\text{все словоформы русского языка}\}, L_5 - \text{русский язык}$. Например, <<Теория формальных языков проста>>$\in L_5$, <<от столом за по телеге>>$\not\in L_5$}
        \end{enumerate}

        Из приведенных примеров видно, что иногда язык удается довольно строго определить имеющимися у нас средствами, однако часто это не удается. Нужны специальные механизмы, описывающие смысл правильных выражений языка. Здесь под смыслом понимается факт принадлежности заданного предложения языку. Важную роль в этом направлении сыграл Ноам Хомский.
      }

  \end{block}
  
\end{frame}

\section{Идея синтаксически-ориентированного разбора Н.Хомского}
\begin{frame}{Идея синтаксически-ориентированного разбора Н.Хомского}
  \begin{block}

    \small{
      Основные идеи Н.Хомского вообще относятся к области лингвистики. В конце 1950 годов лингвисты разрабатывали различные модели естественного языка для решения проблемы автоматического перевода одного естественного языка на другой. Н.Хомский предложил так называемую структурную модель естественного языка, которая рассматривает один узкий аспект языков - их синтаксис и их структуру. Свою модель он построил на основе гипотезы, что все естественные языки столь различны, но в основе их всех лежит некий общий метаязык. Функции порождения и распознавания смысла фраз естественного языка задаются именно правилами этого метаязыка.

      Для обоснования своего подхода Хомский стал анализировать предложения с двойным смыслом: <<Казнить (,) нельзя (,) помиловать>>. Ведь если смысл задается только структурой слов в самом предложении, то изменение этой структуры мгновенно меняет смысл. Однако в дальнейшем Хомский обнаружил, что при неизменности внешней структуры смысл предложений все равно может быть разный. Например,

      <<Порядок сменит хаос>> - толи порядок придет на смену хаосу, толи наоборот?

      <<Он вернулся из командировки в Москву>> - куда он вернулся из Москвы, или в Москву?

      <<Бытие определяет сознание>> - кто-кого определяет?
      }

  \end{block}
  
\end{frame}

\begin{frame}{Идея синтаксически-ориентированного разбора Н.Хомского}
  \begin{block}

    \small{
      Представленные примеры показывают, что для извлечения смысла из этих предложений анализа одной лишь их структуры мало. Значит смысл определяется не внешней структурой этих предложений, а структурой выстроенного над этими предложениями метаязыка. Именно разная структура этих предложений на метаязыке придает им разный смысл.

      В дальнейшем эта идея трансформировалась и нашла широкое применение в информатике при построении трансляторов, хотя в лингвистике модель Хомского признали не все лингвисты. Для информатики эта идея получила название \textbf{синтаксически-ориентированной трансляции}: процесс трансляции выполняется в два основных этапа: 1. модуль, который можно назвать распознавателем, строит структуру входной цепочки, 2. на втором этапе построенная структура используется для генерации выхода, выражающего в той или иной форме смысл входной цепочки.
      }

  \end{block}
  
\end{frame}
\section{Формальные грамматики}
\subsection{Способы задания формальных языков}
\begin{frame}{Способы задания формальных грамматик}
  \begin{block}

    \small{
      Определение языка как подможества множества всех возможных цепочек над конечным словарем является слишком общим и неконструктивным. В основном оно может быть удобно лишь для конечного языка. Для бесконечных языков нужны более выразительные средства - нужно суметь задать бесконечное множество цепочек с комощью какого-либо конечного механизма (алгоритма, устройства, исчисления, набора правил и т.д.). Такие механизмы и называются грамматиками.
      \begin{dfn}
        Любой конечный механизм задания языка называется \textbf{грамматикой}.
      \end{dfn}

      Существуют \textbf{два}   основных способа задания формальных языков.

      \textit{Первый способ - это конечное множество правил порождения за конечное число шагов правильных (имеющих смысл) цепочек языка, причем эти правила не позволяют построить никакую цепочку, не принадлежащую языку. Такой способ имеет наименование \textbf{порождающей грамматики}.}

      \textit{Второй способ - это задание механизма распознавания, который, получив в качестве аргумента любую конечную цепочку над словарем $\Sigma$, за конечное число шагов дает ответ, принадлежит ли эта цепочка определяемому языку или нет. Фактически второй способ  - это некий алгоритм, устройство. Такой способ имеет наименование \textbf{распознающей грамматики}.}
      
      }

  \end{block}
  
\end{frame}

\begin{frame}{Способы задания формальных грамматик}
  \begin{block}

    \small{
      В качестве распознающей грамматики может выступать передача на радио <<Говорим по-русски>>. На вход поступает вопрос, правильно ли говорить так: <<Я скучаю по Вас>>. Конечное число экспертов дает ответ: да, нет.

      Роль распознающей грамматики могут выполнять и различные технические устройства, например, автомат по продаже газировки должен распознать правильную комбинацию монет, чтобы продать Вам газировку.
      
      В качестве порождающей грамматики для наглядности может выступать диктатор (вождь племени): все, что он говорит, и даже все, что может сказать, считается для племени правильным.

      В целом порождающие и распознающие грамматики играют разные, но взаимодополняющие роли. Порождающая грамматика удобна для задания спецификации языка, однако она не является алгоритмом, приводящим к результату за конечное число шагов. Распознающие грамматики наоборот представляются алгоритмом, который оказывается важным для анализа, трансляции цепочек языка в некоторый выход.

      Среди способов задания языка с помощью порождающих грамматик особую популярность получили порождающие грамматики Хомского.
      
      }

  \end{block}
  
\end{frame}
\subsection{Задание порождающих грамматик по Хомскому}
\begin{frame}{Задание порождающих грамматик по Хомскому}
  \begin{block}

    \small{
      В 1956 году американский лингвист Ноам Хомский предложил модель порождающей грамматики, которая весьма удобна для задания искусственных языков. Особенность этой модели состоит в том, что каждой порождаемой цепочке языка эта модель позволяет сопоставить ее структуру.

      \begin{dfn}
        Порождающей грамматикой Хомского $G$ называется кортеж $G=<T,N,S,R>$, где:

        $T$ - конечное непустое мнжество (терминальный словарь). Элементы множества $T$ называются \textbf{терминальными символами};

        $N$ - конечное непустое множество (нетерминальный словарь). Элементы множества $N$ называются \textbf{нетерминальными символами}, множества $T$ и $N$ не пересекаются;

        $S$ - выделенный(специальный) нетерминальный символ $S\in N$, так называемый \textbf{начальный символ};

        $R$ - конечное непустое множество правил (продукций), каждое из которых имеет вид $\alpha\rightarrow \beta$, где $\alpha, \beta$  - цепочки символов из $T\cup N$.
        \end{dfn}
      }

  \end{block}
  
\end{frame}

\begin{frame}{Как грамматика порождает язык?}
  \begin{block}

    \small{
      Языком, порождаемым грамматикой $G$, называется множество цепочек, состоящих только из терминальных символов и выводимх из начального символа грамматики с помощью правил грамматики.

      Рассмотрим, например, грамматику $G=<\{a,b\},\{S\}, S, \{S\rightarrow aSb, S\rightarrow\epsilon\}>$.
      Рассмотрим, какие цепочки терминальных символов можно получать в этой грамматике:
      $$S\Rightarrow aSb\Rightarrow aaSbb\Rightarrow aaaSbbb\Rightarrow aaabbb$$
      В целом, как легко догадаться, данная грамматика задает язык $L=\{a^nb^n: n\geq 0\}$.

      Рассмотрим еще пример: $T=\{a,b,c\}$, $N=\{S,A,B,C\}$, множество $R$ задано набором правил:
      $$S\rightarrow ABC$$
      $$A\rightarrow aA$$
      $$A\rightarrow a$$
      $$B\rightarrow b$$
      $$C\rightarrow Cc$$
      $$C\rightarrow c$$
Попробуйте догадаться, какой язык порождает эта грамматика?
      }

  \end{block}
  
\end{frame}

\begin{frame}{Как грамматика порождает язык?}
  \begin{block}

    \small{
      Часто правила записывают более компактно, перечисляя все альтернативы замены одного и того же нетерминала (разные правые части правил с одинаковой левой частью) с использованием символа |. Так предыдущая грамматика в этом случае может быть записана:
      $$S\rightarrow ABC$$
      $$A\rightarrow aA|a$$
      $$B\rightarrow b$$
      $$C\rightarrow Cc|c$$

      Согласно Хомскому, нетерминалы грамматики представляют собой символы метаязыка, которые играют определенные роли в предложениях языка, а дерево вывода связывает эти роли и их смысловые нагрузки, что позволяет <<вычислить>> смысл всего предложения.

      Нужно отметить, что грамматики могут иметь довольно сложный набор правил, например, $S\rightarrow aSbAc; aS\rightarrow bbAc; bAc\rightarrow B; SbA\rightarrow\epsilon; B\rightarrow b$. При этом грамматики разной сложности могут порождать один и тот же язык. Это все равно, что выразить одинаковый смысл в лаконичной форме, или в очень путанной и сложной. Соответственно возникает вопрос, \textbf{как измерить сложность грамматики и сложность языка?}

      
      }

  \end{block}
  
\end{frame}

\subsection{Классификация порождающих грамматик по Хомскому}
\begin{frame}{Классификация порождающих грамматик по Хомскому}
  \begin{block}

    \small{
      Одна из важных идей Хомского состояла в том, что можно измерить сложность грамматики по сложности ее правил, а сложность языка по сложности наиболее простой грамматики, которая этот язык может задать.  Исходя из этой посылки, Хомский выделил четыре класса грамматик, и соответственно 4 класса сложности языков. Для каждого из классов таких языков впоследствии были найдены (построены) распознающие грамматики (распознаватели). Итак, классификация Хомского включает следующий набор, представленный в порядке убывания сложности (в обозначениях ниже $\alpha,\beta, \gamma$ - цепочки из терминальных и нетерминальных символов; $A,B$ - один нетерминальный символ; $a$ - один терминальный символ).

      \begin{itemize}
      \item{Грамматики типа 0. Данные грамматики называют \textbf{свободными} или неограниченными. Хотя бы одно правило должно быть вида $\alpha\rightarrow\beta$, распознаются только машинами Тьюринга.}
      \item{Грамматики типа 1. Данные грамматики называют \textbf{контекстно-зависимыми} или неукорачивающими. Хотя бы одно правило должно быть вида $\alpha A\beta\rightarrow \alpha\gamma\beta$, распознаются линейно-ограниченными автоматами.}
      \item{Грамматики типа 2. Контекстно-свободные грамматики. Все правила должны быть вида $A\rightarrow \alpha$, распознаются автоматами с магазинной памятью.}
        \item{Грамматики типа 3. Автоматные (регулярные) грамматики. Все правила должны быть вида $A\rightarrow aB|a|\epsilon$, распознаются автоматами с конечными автоматами.}
        \end{itemize}
      }

  \end{block}
  
\end{frame}

\end{document}
